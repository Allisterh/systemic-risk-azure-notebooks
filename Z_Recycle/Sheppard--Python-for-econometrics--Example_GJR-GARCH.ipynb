{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Estimating the Parameters of a GARCH Model   \n",
    "Kevin Sheppard   \n",
    "https://www.kevinsheppard.com/images/0/09/Python_introduction.pdf Chapter 27 Page 333  \n",
    "https://www.kevinsheppard.com/Python_for_Econometrics   \n",
    "https://www.kevinsheppard.com/images/9/9e/Example_GJR-GARCH.ipynb  \n",
    "https://www.kevinsheppard.com/images/1/1b/FTSE_1984_2012.zip   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython Notebook Setup\n",
    "\n",
    "This command is used to set the location of the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\kevin.sheppard\\\\Dropbox\\\\Teaching\\\\Graduate\\\\Python\\\\Python_Introduction\\\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b6858a99765a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\kevin.sheppard\\Dropbox\\Teaching\\Graduate\\Python\\Python_Introduction\\data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\kevin.sheppard\\\\Dropbox\\\\Teaching\\\\Graduate\\\\Python\\\\Python_Introduction\\\\data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\kevin.sheppard\\Dropbox\\Teaching\\Graduate\\Python\\Python_Introduction\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the Parameters of a GARCH Model\n",
    "\n",
    "This example will highlight the steps needed to estimate the parameters of a GJR-GARCH(1,1,1) model with a constant mean. The volatility dynamics in a GJR-GARCH model are given by \n",
    "\n",
    "$$\\sigma_{t}^{2}=\\omega+\\sum_{i=1}^{p}\\alpha_{i}\\epsilon_{t-i}^{2}+\\sum_{j=1}^{o}\\gamma_{j}\\epsilon_{t-j}^{2}I_{\\left[\\epsilon_{t-j}<0\\right]}+\\sum_{k=1}^{q}\\beta_{k}\\sigma_{t-k}^{2}.$$\n",
    "\n",
    "Returns are assumed to be conditionally normal, $r_{t}|\\mathcal{F}_{t-1}\\sim N\\left(\\mu,\\sigma_{t}^{2}\\right)$, $\\epsilon_{t}=r_{t}-\\mu$ and parameters are estimated by maximum likelihood. To estimate the parameters, it is necessary to:\n",
    "\n",
    "1. Produce some starting values\n",
    "2. Estimate the parameters using (quasi-) maximum likelihood\n",
    "3. Compute standard errors using a “sandwich” covariance estimator (also known as the [BollerslevWooldridge::1992] covariance estimator)\n",
    "\n",
    "The first task is to write the log-likelihood which can be used in an optimizer. The log-likelihood function will compute the volatility recursion and the log-likelihood. It will also, optionally, return the $T$ by 1 vector of individual log-likelihoods which are useful when approximating the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from numpy import size, log, pi, sum, diff, array, zeros, diag, dot, mat, asarray, sqrt, copy\n",
    "from numpy.linalg import inv\n",
    "from pandas import read_csv\n",
    "from scipy.optimize import fmin_slsqp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional log-likelihood of a normal random variable is\n",
    "\n",
    "$$\\ln f\\left(r_{t}|\\mu,\\sigma_{t}^{2}\\right)=-\\frac{1}{2}\\left(\\ln2\\pi+\\ln\\sigma_{t}^{2}+\\frac{\\left(r_{t}-\\mu\\right)^{2}}{\\sigma_{t}^{2}}\\right),$$\n",
    "\n",
    "which is negated in the code since the optimizers all minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gjr_garch_likelihood(parameters, data, sigma2, out=None):\n",
    "          ''' Returns negative log-likelihood for GJR-GARCH(1,1,1) model.'''\n",
    "          mu = parameters[0]\n",
    "          omega = parameters[1]\n",
    "          alpha = parameters[2]\n",
    "          gamma = parameters[3]\n",
    "          beta = parameters[4]\n",
    "          \n",
    "          T = size(data,0)\n",
    "          eps = data - mu,\n",
    "          # Data and sigma2 are T by 1 vectors,\n",
    "          for t in xrange(1,T):\n",
    "              sigma2[t] = (omega + alpha * eps[t-1]**2 \n",
    "                           + gamma * eps[t-1]**2 * (eps[t-1]<0) + beta * sigma2[t-1])\n",
    "          \n",
    "          logliks = 0.5*(log(2*pi) + log(sigma2) + eps**2/sigma2)\n",
    "          loglik = sum(logliks)\n",
    "          \n",
    "          if out is None:\n",
    "              return loglik\n",
    "          else:\n",
    "              return loglik, logliks, copy(sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword argument `out` has a default value of `None`, and is used to determine whether to return 1 output or 3. This is common practice since the optimizer requires a single output -- the log-likelihood function value, but it is also useful to be able to output other useful quantities, such as $\\left\\{ \\sigma_{t}^{2}\\right\\}$.\n",
    "\n",
    "The optimization is constrained so that $\\alpha+\\gamma/2+\\beta\\leq 1$, and the constraint is provided in a separate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gjr_constraint(parameters, data, sigma2, out=None):\n",
    "    ''' Constraint that alpha+gamma/2+beta<=1'''\n",
    "    alpha = parameters[2]\n",
    "    gamma = parameters[3]\n",
    "    beta = parameters[4]\n",
    "    return array([1-alpha-gamma/2-beta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the constraint function takes the same inputs as the negative of the log-likelihood function, even though only parameters is required to compute the constraint.\n",
    "\n",
    "It is necessary to discuss one other function before proceeding with the main block of code. The asymptotic variance is estimated using the “sandwich” form which is commonly expressed as\n",
    "\n",
    "$$\\mathcal{J}^{-1}\\mathcal{I}\\mathcal{J}^{-1}$$\n",
    "\n",
    "where $\\mathcal{J}$ is the expected Hessian and $\\mathcal{I}$ is the covariance of the scores. Both are numerically approximated, and the strategy for computing the Hessian is to use the definition that \n",
    "\n",
    "$$\\mathcal{J}_{ij}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}+e_{j}h_{j}\\right)-f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta+e_{j}h_{j}\\right)+f\\left(\\theta\\right)}{h_{i}h_{j}}$$\n",
    "\n",
    "where $h_{i}$ is a scalar “step size” and $e_{i}$ is a vector of 0s except for element $i$, which is 1. A 2-sided version of this approximation, which takes both forward and backward steps and then averages, is below. For more on numerical derivatives, see [FlanneryPressTeukolskyTeukolsky::1992]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hessian_2sided(fun, theta, args):\n",
    "    f = fun(theta, *args)\n",
    "    h = 1e-5*np.abs(theta)\n",
    "    thetah = theta + h\n",
    "    h = thetah - theta\n",
    "    K = size(theta,0)\n",
    "    h = np.diag(h)\n",
    "    fp = zeros(K)\n",
    "    fm = zeros(K)\n",
    "    for i in xrange(K):\n",
    "        fp[i] = fun(theta+h[i], *args)\n",
    "        fm[i] = fun(theta-h[i], *args)\n",
    "    fpp = zeros((K,K))\n",
    "    fmm = zeros((K,K))\n",
    "    for i in xrange(K):\n",
    "        for j in xrange(i,K):\n",
    "            fpp[i,j] = fun(theta + h[i] + h[j], *args)\n",
    "            fpp[j,i] = fpp[i,j]\n",
    "            fmm[i,j] = fun(theta - h[i] - h[j], *args)\n",
    "            fmm[j,i] = fmm[i,j]\n",
    "    hh = (diag(h))\n",
    "    hh = hh.reshape((K,1))\n",
    "    hh = dot(hh,hh.T)\n",
    "    H = zeros((K,K))\n",
    "    for i in xrange(K):\n",
    "        for j in xrange(i,K):\n",
    "            H[i,j] = (fpp[i,j] - fp[i] - fp[j] + f\n",
    "                        + f - fm[i] - fm[j] + fmm[i,j])/hh[i,j]/2\n",
    "            H[j,i] = H[i,j]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the code that does the actual work can be written. The first block imports the data, flips it using a slicing operator, and computes 100 times returns. Scaling data can be useful to improve optimizer performance, and ideally estimated parameters should have similar magnitudes (i.e. $\\omega\\approx.01$  and $\\alpha\\approx.05$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'FTSE_1984_2012.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-949e6b4f6782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mFTSEdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FTSE_1984_2012.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Flip upside down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFTSEdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFTSEdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Compute returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'FTSE_1984_2012.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "FTSEdata = read_csv('FTSE_1984_2012.csv', parse_dates=[0])\n",
    "# Flip upside down\n",
    "FTSEdata = FTSEdata[::-1]\n",
    "# Compute returns\n",
    "FTSEprice = FTSEdata['Adj Close']\n",
    "FTSEreturn = 100*diff(log(FTSEprice).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good starting values are important. These are my guesses based on experience fitting these types of models models. An alternative is to attempt a crude grid search and use the best (smallest) log-likelihood value from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FTSEreturn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8db7bcb994eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Starting values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstartingVals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFTSEreturn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFTSEreturn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FTSEreturn' is not defined"
     ]
    }
   ],
   "source": [
    "# Starting values\n",
    "startingVals = array([FTSEreturn.mean(),FTSEreturn.var() * .01, .03, .09, .90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounds are used in estimation to ensure that all parameters in the conditional variance are $\\geq 0$  and to set sensible upper bounds on the mean and $\\omega$. The vector `sigma2` is then initialized, and the arguments are placed in a tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate parameters\n",
    "finfo = np.finfo(np.float64)\n",
    "bounds = [(-10*FTSEreturn.mean(), 10*FTSEreturn.mean()), (finfo.eps, 2*FTSEreturn.var()), (0.0,1.0), (0.0,1.0), (0.0,1.0)]\n",
    "T = size(FTSEreturn,0)\n",
    "sigma2 = np.repeat(FTSEreturn.var(),T)\n",
    "args = (FTSEreturn, sigma2)\n",
    "estimates = fmin_slsqp(gjr_garch_likelihood, startingVals, f_ieqcons=gjr_constraint, bounds = bounds, args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized log-likelihood and the time series of variances are computed by calling the objective using the keyword argument `out=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-53c6fc5a2dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloglik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogliks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma2final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgjr_garch_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFTSEreturn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'estimates' is not defined"
     ]
    }
   ],
   "source": [
    "loglik, logliks, sigma2final = gjr_garch_likelihood(estimates, FTSEreturn, sigma2, out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the numerical scores and the covariance of the scores are computed. These exploit the definition of a derivative, so that for a scalar function, \n",
    "\n",
    "$$\\frac{\\partial f\\left(\\theta\\right)}{\\partial\\theta_{i}}\\approx\\frac{f\\left(\\theta+e_{i}h_{i}\\right)-f\\left(\\theta\\right)}{h_{i}}.$$\n",
    " \n",
    "The covariance is computed as the outer product of the scores since the scores should have mean 0 when evaluated at the solution to the optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step = 1e-5 * estimates\n",
    "scores = np.zeros((T,5))\n",
    "for i in xrange(5):\n",
    "    h = step[i]\n",
    "    delta = np.zeros(5)\n",
    "    delta[i] = h\n",
    "    loglik, logliksplus, sigma2 = gjr_garch_likelihood(estimates + delta, FTSEreturn, sigma2, out=True)\n",
    "    loglik, logliksminus, sigma2 = gjr_garch_likelihood(estimates - delta, FTSEreturn, sigma2, out=True)\n",
    "    scores[:,i] = (logliksplus - logliksminus)/(2*h)\n",
    "I = np.dot(scores.T,scores)/T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block calls `hessian_2sided` to estimate the Hessian, and then computes the asymptotic covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J = hessian_2sided(gjr_garch_likelihood, estimates, args)\n",
    "J = J/T\n",
    "Jinv = mat(inv(J))\n",
    "vcv = Jinv*mat(I)*Jinv/T\n",
    "vcv = asarray(vcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penultimate step is to pretty print the results and to produce a plot of the conditional variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = np.vstack((estimates,sqrt(diag(vcv)),estimates/sqrt(diag(vcv)))).T\n",
    "print('Parameter Estimate Std. Err. T-stat')\n",
    "param = ['mu','omega','alpha','gamma','beta']\n",
    "for i in xrange(len(param)):\n",
    "print('{0:<11} {1:>0.6f} {2:0.6f} {3: 0.5f}'.format(param[i],output[i,0],output[i,1],,output[i,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final block produces a plot of the annualized conditional standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = FTSEdata.Date[1:]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "volatility = pd.DataFrame(np.sqrt(252 * sigma2), index=dates)\n",
    "ax.plot(volatility.index,volatility)\n",
    "ax.autoscale(tight='x')\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout(pad=1.5)\n",
    "ax.set_ylabel(’Volatility’)\n",
    "ax.set_title(’FTSE Volatility (GJR GARCH(1,1,1))')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
