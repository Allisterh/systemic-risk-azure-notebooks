{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Py-CIMDO-PoD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for estimating time-series of probabilities of distress (or default) using python [pandas](https://pandas.pydata.org/).    \n",
    "The method is described in the Appendix I of [(Cortes, Lindner, Malik and Segoviano 2018)](https://www.imf.org/en/Publications/WP/Issues/2018/01/24/A-Comprehensive-Multi-Sector-Tool-for-Analysis-of-Systemic-Risk-and-Interconnectedness-SyRIN-45580)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to display markdown files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project sub-folder (`CIMDO/markdown`) has some common resources that can be automatically imported into notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "def display_markdown(filename):\n",
    "    f = open(filename, 'r')\n",
    "    return(display(Markdown(f.read())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Consistent Information Multivariate Density Optimizing Methodology (CIMDO) (Segoviano 2006, Segoviano and Espinoza 2017) is a methodology to infer multivariate densities that describe the  a system of asset values, typically of financial institutions, and applies it to quantify systemic risk. The CIMDO density, is inferred from partial information but is consistent with the observed probabilities of distress of financial institutions. From the density various useful metrics of systemic risk can be calculated easily.   \n",
       "In a more recent incarnation the CIMDO engine is used to build the Systemic Risk and Interconnectness (SyRIN) tool (Cortes, Lindner, Malik & Segoviano 2018), which measures systemic risk by looking at interconnectedness between institutions and sectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown('markdown/Overview.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate PoDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoDs: Products and Investment Funds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some random returns data, for test purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "s = pd.Series(np.random.randn(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `DataFrame` time-series with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeSeries():\n",
    "    date_today = datetime.now()\n",
    "    dates = pd.date_range(date_today, date_today + timedelta(50), freq='D')\n",
    "    np.random.seed(seed=0)\n",
    "    data = np.random.randn(len(dates))\n",
    "    df = pd.DataFrame({'Date': dates, 'Value': data})\n",
    "    df = df.set_index('Date')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=createTimeSeries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a time-series (either as a `series` or `DataFrame`) of values (returns, not P&Ls) estimate the time series of probabilities of distress (PoDs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize using `pipe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipe` method to apply transformations to series elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize = lambda x: (x-x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.pipe(standardize).head(5)\n",
    "# df.pipe(standardize).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `rolling` window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rolling` method can be chained with `apply` to apply arbitrary aggregation functions to the window (sub-series) of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4    7.251399\n",
       "5    4.510069\n",
       "6    5.060000\n",
       "7    3.929905\n",
       "8    1.585792\n",
       "9    0.128833\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s.rolling(5).sum().head(10)\n",
    "s.rolling(5).apply(sum).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for `DataFrame`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rolling(5).std().rename(columns = {'Value':'Std'}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of distress by counting `PoD_count`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply counting the outcomes that are less than the threshold does not require any assumption of the distribution. However, for short horizons and small quantiles, the accuracy will be poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoD_count(s, distress_threshold):\n",
    "    \"\"\"Find probability of distress by counting outcomes below distress_threshold\"\"\"\n",
    "    n = np.count_nonzero(s)\n",
    "    m = np.count_nonzero(s < distress_threshold)\n",
    "    return(m/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5     NaN\n",
       "6     NaN\n",
       "7     NaN\n",
       "8     NaN\n",
       "9     0.2\n",
       "10    0.2\n",
       "11    0.1\n",
       "12    0.1\n",
       "13    0.2\n",
       "14    0.3\n",
       "15    0.4\n",
       "16    0.4\n",
       "17    0.4\n",
       "18    0.4\n",
       "19    0.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distress_threshold = -1.0\n",
    "s.rolling(10).apply(lambda s: PoD_count(s,distress_threshold)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of distress by assuming normal distribution `PoD_norm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this approach requires us to assume a Gaussian distribution, the sampling error will be reasonable, even for small quantiles & short horizons. This is the approach advocated by (Cortes et al 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoD_norm(s, distress_threshold):\n",
    "    \"\"\"Find probability of distress - i.e. falling below distress_threshold - by assuming normal distribution\"\"\"\n",
    "    loc = s.mean()\n",
    "    scale = s.std()\n",
    "    pod = norm.pdf(distress_threshold, loc, scale)\n",
    "    #m = np.count_nonzero(s < distress_threshold)\n",
    "    return(pod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          NaN\n",
       "2          NaN\n",
       "3          NaN\n",
       "4          NaN\n",
       "5          NaN\n",
       "6          NaN\n",
       "7          NaN\n",
       "8          NaN\n",
       "9     0.227082\n",
       "10    0.197554\n",
       "11    0.181487\n",
       "12    0.196752\n",
       "13    0.221794\n",
       "14    0.241253\n",
       "15    0.245524\n",
       "16    0.243667\n",
       "17    0.311096\n",
       "18    0.302463\n",
       "19    0.301570\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distress_threshold = -1.0\n",
    "s.rolling(10).apply(lambda s:PoD_norm(s,distress_threshold)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PoD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoD(s,alpha,horizon):\n",
    "    \"\"\"Find the probability of distress time-series for quantile alpha & rolling horizon\"\"\"\n",
    "    distress_threshold = s.quantile(alpha)\n",
    "    pod = s.rolling(10).apply(lambda s:PoD_norm(s,distress_threshold))\n",
    "    return(pod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-23 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-24 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-25 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-26 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-27 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-28 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-29 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-30 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 20:04:31.912428</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01 20:04:31.912428</th>\n",
       "      <td>0.019063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-02 20:04:31.912428</th>\n",
       "      <td>0.022126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-03 20:04:31.912428</th>\n",
       "      <td>0.020106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-04 20:04:31.912428</th>\n",
       "      <td>0.020762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:04:31.912428</th>\n",
       "      <td>0.014592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-06 20:04:31.912428</th>\n",
       "      <td>0.005343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Value\n",
       "Date                                \n",
       "2018-08-23 20:04:31.912428       NaN\n",
       "2018-08-24 20:04:31.912428       NaN\n",
       "2018-08-25 20:04:31.912428       NaN\n",
       "2018-08-26 20:04:31.912428       NaN\n",
       "2018-08-27 20:04:31.912428       NaN\n",
       "2018-08-28 20:04:31.912428       NaN\n",
       "2018-08-29 20:04:31.912428       NaN\n",
       "2018-08-30 20:04:31.912428       NaN\n",
       "2018-08-31 20:04:31.912428       NaN\n",
       "2018-09-01 20:04:31.912428  0.019063\n",
       "2018-09-02 20:04:31.912428  0.022126\n",
       "2018-09-03 20:04:31.912428  0.020106\n",
       "2018-09-04 20:04:31.912428  0.020762\n",
       "2018-09-05 20:04:31.912428  0.014592\n",
       "2018-09-06 20:04:31.912428  0.005343"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Works for series or DataFrame\n",
    "PoD(df,0.05,20).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIMDO implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Py-CIMDO](https://notebooks.azure.com/ian-buckley/libraries/systemic-risk/html/CIMDO/Py-CIMDO.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "* Cortes, Fabio, Peter H. Lindert, Sheheryar Malik, and Miguel Segoviano Basurto. 2018. “A Comprehensive Multi-Sector Tool for Analysis of Systemic Risk and Interconnectedness (SyRIN).”    \n",
       "* MathWorks. 2014. CIMDO Optimization in Matlab. https://www.mathworks.com/matlabcentral/answers/115886-optimization-problem-reducing-the-time-needed-to-solve.    \n",
       "* Segoviano Basurto, Miguel A. 2006. “Portfolio Credit Risk and Macroeconomic Shocks; Applications to Stress Testing Under Data-Restricted Environments.” IMF Working Paper 06/283. International Monetary Fund. https://ideas.repec.org/p/imf/imfwpa/06-283.html.    \n",
       "* Segoviano, Miguel. 2008. “The CIMDO Copula. Modeling of a Non-Parametric Copula.” International Monetary Fund, Forthcoming Working Paper.    \n",
       "* Segoviano, Miguel, and Charles Goodhart. 2009. “Banking Stability Measures.” FMG Discussion Paper. Financial Markets Group. http://econpapers.repec.org/paper/fmgfmgdps/dp627.htm.     \n",
       "* ———. 2016. “An Encompassing Framework to Estimate Systemic Risk Amplification Losses Based on Publicly Available Information.” https://www.imf.org/~/media/Files/News/Seminars/mcm-lse-segoviano_session4.ashx.    \n",
       "* Segoviano, Miguel A., and Raphael A. Espinoza. 2011. “Financial Stability Measures.” http://www.lse.ac.uk/fmg/events/conferences/past-conferences/2011/systemicRisk_24-25Jan2011/MSegoviano_Presentation.pdf."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown('markdown/FurtherReading.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
